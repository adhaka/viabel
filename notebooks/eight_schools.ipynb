{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy.stats.norm as norm\n",
    "\n",
    "from viabel.vb import mean_field_t_variational_family, mean_field_gaussian_variational_family\n",
    "from viabel.vb import make_stan_log_density, adagrad_optimize\n",
    "from experiments import run_experiment\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook', font_scale=2, rc={'lines.linewidth': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viabel.vb import  full_rank_gaussian_variational_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t \n",
    "from itertools import product\n",
    "from scipy.stats import t\n",
    "from experiments import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viabel.vb import  rmsprop_IA_optimize_with_rhat, adam_IA_optimize_with_rhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../figures', exist_ok=True)\n",
    "\n",
    "logtau_lim = [-2, 3.5]\n",
    "mu_lim = [-5, 15]\n",
    "theta1_lim = [-8, 22]\n",
    "\n",
    "skip = 1 # how much to thin samples; larger values make the plots faster but let accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_contours(x_samples1, y_samples1, x_samples2, y_samples2, xlabel, ylabel, xlim, ylim, \n",
    "                    cmap1, cmap2, savepath=None, **kwargs):\n",
    "    sns.kdeplot(x_samples1, y_samples1, cmap=cmap1, **kwargs)\n",
    "    sns.kdeplot(x_samples2, y_samples2, cmap=cmap2, **kwargs)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if savepath is not None:\n",
    "        plt.savefig(savepath, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_sample_and_density_contours(x_samples, y_samples, logdensity, xlabel, ylabel, xlim, ylim, \n",
    "                    cmap_samples, cmap_density, savepath=None, **kwargs):\n",
    "    sns.kdeplot(x_samples, y_samples, cmap=cmap_samples, **kwargs)\n",
    "    x = np.linspace(*xlim, 100)\n",
    "    y = np.linspace(*ylim, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    XY = np.concatenate([X[:,:,np.newaxis], Y[:,:,np.newaxis]], axis=2)\n",
    "    Z = np.exp(logdensity(XY))\n",
    "    plt.contour(X, Y, Z, cmap=cmap_density, linestyles='solid')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if savepath is not None:\n",
    "        plt.savefig(savepath, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def tranform_to_theta(ncp_samples):\n",
    "    ncp_samples_tranformed = ncp_samples.copy()\n",
    "    ncp_samples_tranformed[2:] = (ncp_samples_tranformed[0] \n",
    "                                  + np.exp(ncp_samples_tranformed[1]) * ncp_samples_tranformed[2:])\n",
    "    return ncp_samples_tranformed\n",
    "\n",
    "def get_ncp_approx_samples(var_family, opt_param, n_samples):\n",
    "    ncp_samples = var_family.sample(opt_param, n_samples).T\n",
    "    return ncp_samples, tranform_to_theta(ncp_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params_cp=10\n",
    "var_family_cp = mean_field_t_variational_family(n_params_cp, 40)\n",
    "gaussian_mf_var_family_cp = mean_field_gaussian_variational_family(n_params_cp)\n",
    "gaussian_fr_var_family_cp = full_rank_gaussian_variational_family(n_params_cp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55,)\n",
      "(55, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-82.71472820031981"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_param_cp_fr = np.concatenate([np.ones(n_params_cp), .5*np.ones(int(n_params_cp*(n_params_cp+1)/2))])\n",
    "gaussian_fr_var_family_cp.sample(init_param_cp_fr, n_samples=1)\n",
    "init_param_cp_mf = np.concatenate([np.ones(n_params_cp), .5*np.ones(n_params_cp)])\n",
    "a = gaussian_mf_var_family_cp.sample(init_param_cp_mf, n_samples=1)\n",
    "#gaussian_mf_var_family_cp.logdensity(a, init_param_cp_mf) \n",
    "gaussian_fr_var_family_cp.logdensity(a, init_param_cp_fr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    eight_schools_cp_stan_model = pickle.load(open('eight_schools_cp1.pkl', 'rb'))\n",
    "    #eight_schools_cp_stan_model = pystan.StanModel(file='eight_schools_cp.stan' ,\n",
    "    #                                           model_name='eight_schools_cp')\n",
    "except:\n",
    "    eight_schools_cp_stan_model = pystan.StanModel(file='eight_schools_cp.stan', model_name='eight_schools_cp')\n",
    "    with open('eight_schools_cp1.pkl', 'wb') as f:\n",
    "        pickle.dump(eight_schools_cp_stan_model, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    eight_schools_ncp_stan_model = pickle.load(open('eight_schools_ncp1.pkl', 'rb'))\n",
    "    #eight_schools_ncp_stan_model = pystan.StanModel(file='eight_schools_ncp.stan' ,\n",
    "    #                                           model_name='eight_schools_ncp')\n",
    "except:\n",
    "    eight_schools_ncp_stan_model = pystan.StanModel(file='eight_schools_ncp.stan', model_name='eight_schools_ncp')\n",
    "    with open('eight_schools_ncp1.pkl', 'wb') as f:\n",
    "        pickle.dump(eight_schools_ncp_stan_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the Eight Schools Model\n",
    "J = 8\n",
    "y = np.array([28.,  8., -3.,  7., -1.,  1., 18., 12.])\n",
    "sigma = np.array([15., 10., 16., 11.,  9., 11., 10., 18.])\n",
    "data = dict(J=J, y=y, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:259 of 40000 iterations ended with a divergence (0.647 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.99 to remove the divergences.\n",
      "WARNING:pystan:Chain 1: E-BFMI = 0.161\n",
      "WARNING:pystan:Chain 2: E-BFMI = 0.177\n",
      "WARNING:pystan:Chain 4: E-BFMI = 0.196\n",
      "WARNING:pystan:E-BFMI below 0.2 indicates you may need to reparameterize your model\n"
     ]
    }
   ],
   "source": [
    "eight_schools_cp_fit = eight_schools_cp_stan_model.sampling(data=data, iter=11000, warmup=1000,\n",
    "                                                            control=dict(adapt_delta=.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight_schools_ncp_fit = eight_schools_ncp_stan_model.sampling(data=data, iter=32000, warmup=2000, thin=3,\n",
    "                                                              control=dict(adapt_delta=.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: eight_schools_ncp_ae46705580739ef95b05e742166c14cd.\n",
       "4 chains, each with iter=32000; warmup=2000; thin=3; \n",
       "post-warmup draws per chain=10000, total post-warmup draws=40000.\n",
       "\n",
       "                 mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "mu               4.36    0.02   3.31  -2.17   2.14   4.38   6.62   10.8  40318    1.0\n",
       "tau              3.57    0.02   3.17   0.12   1.26   2.74   4.94  11.73  39389    1.0\n",
       "theta_tilde[1]   0.32  5.0e-3   0.99  -1.63  -0.35   0.33    1.0   2.24  39891    1.0\n",
       "theta_tilde[2]   0.11  4.7e-3   0.94  -1.75  -0.53   0.12   0.74   1.94  40195    1.0\n",
       "theta_tilde[3]   -0.1  4.8e-3   0.97  -1.99  -0.75   -0.1   0.56    1.8  40422    1.0\n",
       "theta_tilde[4]   0.06  4.7e-3   0.95  -1.81  -0.57   0.06    0.7   1.93  40130    1.0\n",
       "theta_tilde[5]  -0.16  4.7e-3   0.93  -1.99  -0.78  -0.17   0.45    1.7  40235    1.0\n",
       "theta_tilde[6]  -0.06  4.7e-3   0.95  -1.92  -0.69  -0.06   0.57   1.83  40687    1.0\n",
       "theta_tilde[7]   0.36  4.8e-3   0.96  -1.58  -0.29   0.38   1.01    2.2  40206    1.0\n",
       "theta_tilde[8]   0.08  4.8e-3   0.98  -1.84  -0.58   0.08   0.74   1.97  41049    1.0\n",
       "theta[1]         6.16    0.03   5.58  -3.14    2.7   5.61   8.85  19.42  41261    1.0\n",
       "theta[2]         4.93    0.02   4.66  -4.05   2.04   4.84   7.67  14.68  40440    1.0\n",
       "theta[3]         3.85    0.03   5.27  -7.71   1.04   4.09   7.01  13.76  40490    1.0\n",
       "theta[4]         4.72    0.02   4.78   -4.8   1.82   4.69   7.55  14.55  41162    1.0\n",
       "theta[5]         3.59    0.02   4.64  -6.66    0.9   3.83    6.6   12.1  40618    1.0\n",
       "theta[6]         4.05    0.02   4.78  -6.12   1.29   4.22   7.04  13.08  39964    1.0\n",
       "theta[7]         6.24    0.03   5.03  -2.43   2.98   5.78    8.9  17.95  40275    1.0\n",
       "theta[8]         4.84    0.03   5.27  -5.49   1.79   4.74   7.73  15.88  41667    1.0\n",
       "lp__            -6.97    0.01   2.36  -12.5  -8.32  -6.65  -5.26  -3.32  34125    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Wed Apr 22 18:27:41 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eight_schools_ncp_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of parameters and parameter names in centered model\n",
    "n_params_cp = len(eight_schools_cp_fit.constrained_param_names())\n",
    "param_names_cp = ['mu', 'log_tau'] + eight_schools_cp_fit.flatnames[2:n_params_cp]\n",
    "\n",
    "# number of parameters and parameter names in non-centered model\n",
    "n_params_ncp = len(eight_schools_ncp_fit.constrained_param_names())\n",
    "param_names_ncp = ['mu', 'log_tau'] + eight_schools_ncp_fit.flatnames[2:n_params_ncp]\n",
    "param_names_ncp_transformed = ['mu', 'log_tau'] + eight_schools_ncp_fit.flatnames[n_params_ncp:]\n",
    "\n",
    "# the centered and tranformed non-centered parameters should be the same\n",
    "#np.testing.assert_array_equal(param_names_cp, param_names_ncp_transformed)\n",
    "\n",
    "# construct matrix of samples (both original and transformed) from non-centered model \n",
    "samples_ncp_df = eight_schools_ncp_fit.to_dataframe(pars=eight_schools_ncp_fit.flatnames)\n",
    "samples_ncp_df['log_tau'] = np.log(samples_ncp_df['tau'])\n",
    "samples_ncp = samples_ncp_df.loc[:,param_names_ncp].values.T\n",
    "samples_ncp_transformed = samples_ncp_df.loc[:,param_names_ncp_transformed].values.T\n",
    "\n",
    "# use samples from non-centered model for ground true mean and covariance\n",
    "true_mean_ncp = np.mean(samples_ncp, axis=1)\n",
    "true_cov_ncp = np.cov(samples_ncp)\n",
    "true_mean_ncp_tranformed = np.mean(samples_ncp_transformed, axis=1)\n",
    "true_cov_ncp_tranformed = np.cov(samples_ncp_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight_schools_cp_log_density = make_stan_log_density(eight_schools_cp_fit)\n",
    "\n",
    "eight_schools_ncp_log_density = make_stan_log_density(eight_schools_ncp_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------------|\n",
      "|     KLVI     |\n",
      "|--------------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 8.5925: 100%|██████████| 10000/10000 [00:38<00:00, 260.09it/s]\n",
      "/anaconda3/envs/viabel_env/lib/python3.6/site-packages/autograd/tracer.py:48: RuntimeWarning: invalid value encountered in log\n",
      "  return f_raw(*args, **kwargs)\n",
      "../viabel/optimization_diagnostics.py:148: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  real_idxs = weights >= 10 * np.finfo(float).eps\n",
      "../viabel/optimization_diagnostics.py:161: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  sigma = -k_post / b_post\n",
      "/anaconda3/envs/viabel_env/lib/python3.6/site-packages/autograd/tracer.py:48: RuntimeWarning: invalid value encountered in log1p\n",
      "  return f_raw(*args, **kwargs)\n",
      "/anaconda3/envs/viabel_env/lib/python3.6/site-packages/autograd/tracer.py:48: RuntimeWarning: overflow encountered in exp\n",
      "  return f_raw(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-53867afb532c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                    \u001b[0mtrue_mean_ncp_tranformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_cov_ncp_tranformed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                    \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                    n_iters=10000, bound_w2=2500000, verbose=True)\n\u001b[0m",
      "\u001b[0;32m~/Desktop/research_repos/viabel/viabel/notebooks/experiments.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(logdensity, var_family, init_param, true_mean, true_cov, kl_n_samples, chivi_n_samples, alpha, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     kl_results, other_kl_results = _optimize_and_check_results(\n\u001b[1;32m    201\u001b[0m         \u001b[0mlogdensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_family\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         true_mean, true_cov, plot_contours, '-ELBO', **kwargs)\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0mkl_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'method'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'KLVI'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research_repos/viabel/viabel/notebooks/experiments.py\u001b[0m in \u001b[0;36m_optimize_and_check_results\u001b[0;34m(logdensity, var_family, objective_and_grad, init_var_param, true_mean, true_cov, plot_contours, ylabel, contour_kws, elbo, n_iters, bound_w2, verbose, use_psis, n_psis_samples, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                                 n_psis_samples=1000000, **kwargs):\n\u001b[1;32m    147\u001b[0m     \u001b[0mopt_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_param_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0madagrad_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective_and_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_var_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0mplot_dist_to_opt_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_param_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     accuracy_results = check_approx_accuracy(var_family, opt_param,\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "\n",
    "var_family_cp = mean_field_t_variational_family(n_params_cp, 40)\n",
    "\n",
    "init_param_cp = np.concatenate([true_mean_ncp_tranformed, .5*np.log(np.diag(true_cov_ncp_tranformed))])\n",
    "klvi_cp, chivi_cp, klvi_cp_results, chivi_cp_results, other_klvi_cp_results, other_chivi_cp_results = \\\n",
    "    run_experiment(eight_schools_cp_log_density, var_family_cp, init_param_cp, \n",
    "                   true_mean_ncp_tranformed, true_cov_ncp_tranformed, \n",
    "                   learning_rate=.01, learning_rate_end=.001,\n",
    "                   n_iters=10000, bound_w2=2500000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight_schools_cp_log_density = make_stan_log_density(eight_schools_cp_fit)\n",
    "t_var_family_cp = mean_field_t_variational_family(n_params_cp, 40)\n",
    "mean_gauss_var_family_cp = mean_field_gaussian_variational_family(n_params_cp)\n",
    "init_param_cp2 = np.concatenate([true_mean_ncp_tranformed, .5*np.log(np.diag(true_cov_ncp_tranformed))])\n",
    "k=10\n",
    "klvi_objective_and_grad = black_box_klvi(var_family_cp, eight_schools_cp_log_density, 100)\n",
    "klvi_objective_and_grad_gaussian = black_box_klvi(mean_gauss_var_family_cp, eight_schools_ncp_log_density, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klvi_var_param_rms, avg_klvi_var_param_list_rms,_, klvi_history_rms, _, op_log_rms = \\\n",
    "    rmsprop_IA_optimize_with_rhat(30000, klvi_objective_and_grad_gaussian, init_param_cp2, k, learning_rate=.01, rhat_window=1000, n_optimisers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_klvi_var_param_rms, gauss_avg_klvi_var_param_list_rms,_, gauss_klvi_history_rms, _, gauss_op_log_rms = \\\n",
    "    rmsprop_IA_optimize_with_rhat(30000, klvi_objective_and_grad, init_param_cp2, k, learning_rate=.01, rhat_window=1000, n_optimisers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(klvi_history_rms[25000:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(op_log_rms['r_hat_mean'])\n",
    "\n",
    "print(op_log_rms['r_hat_sigma'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_results_plot(other_results, method):\n",
    "    if method not in ['klvi', 'chivi']:\n",
    "        print('invalid method \"{}\"'.format(method))\n",
    "        return\n",
    "    cp_opt_param = other_results['opt_param']\n",
    "    cp_mean, cp_log_scale = cp_opt_param[:n_params_cp], cp_opt_param[n_params_cp:]\n",
    "    cp_log_density = lambda x: np.sum(t.logpdf(x, 40, cp_mean[np.newaxis,np.newaxis,1:3], \n",
    "                                               np.exp(cp_log_scale[np.newaxis,np.newaxis,1:3])), axis=-1)\n",
    "    cmap2 = 'Reds' if method == 'klvi' else 'Blues'\n",
    "    plot_sample_and_density_contours(\n",
    "        np.log(eight_schools_ncp_fit['tau'][::skip]), eight_schools_ncp_fit['theta[1]'][::skip],\n",
    "        cp_log_density, r'$\\log(\\tau)$', r'$\\theta_1$', \n",
    "        logtau_lim, theta1_lim, 'Greys', cmap2,\n",
    "        '../figures/8-schools-cp-log-tau-vs-theta1-{}.pdf'.format(method))\n",
    "\n",
    "cp_results_plot(other_klvi_cp_results, 'klvi')\n",
    "cp_results_plot(other_chivi_cp_results, 'chivi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (viabel_env)",
   "language": "python",
   "name": "viabel_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
